# CIS 2520 F21 Assignment 1: Hapax Legomena

This assignment will build upon your programming skills using pointers
and arrays that you learned in earlier programming courses.  We will do
this in the context of building a natural language processing tool that
counts how often each word in a document occurs.  This is a common task
within the artificial intelligence field.

## What are "hapax legomena"

Our tool will tally how many occurrences of each word there is in each
data file presented on the command line, but our underlying objective
is to list the *hapax legomena*.  Each *hapax legomenon* (the singular
form of this term) is a word that occurs **only once** in an entire
document.

From a processing point of view, however, we don't know
whether any given word is going to occur again until we have processed
every word in the entire document. Therefore so we have to:

* keep track of all of the words, and
* for each word, keep track of a counter indicating how many times it has occurred.

## Intended program function

Our program will take information from the command line in order to
determine how it operates.  The usage key for our program is this:

	Usage:
	    hapax [<options>] <datafile> [ <datafile> ...]

	Options:
	-d     : print out all data loaded before printing hapax legomena.
	-h     : this help.  You are looking at it.
	-l <N> : only print hapax legomena of length <N>.
	       : If no -l option is given, all hapax legomena are printed.


(Note that in program usage statements, the use of `[` `]` brackets indicates
an optional item, and items in `<` `>` brackets indicate a value.
This means that the above is saying that all of the options are, well, optional;
the "`<datafile>`" arguments can optionally be in a list with many filenames; and
the "`-l`" argument takes a number following the argument as a value indicating the length.)


Running the program will print out the hapax legomenon from one or more
data files (of only the desired length if indicated).

Let us say the file "`smalldata.txt`" has this content:

	hello where, hello there
	this is a test
	line three



If we run our "`hapax`" program on this file, this is the output we should see:

	$ ./hapax smalldata.txt 
	Total word count 10
	Tally loaded
	Hapax legomena from file 'smalldata.txt':
		a
		is
		line
		test
		this
		three
		there
		where
	$ ./hapax -l 3 smalldata.txt 
	Total word count 10
	Tally loaded
	Hapax legomena from file 'smalldata.txt':
	$ ./hapax -l 4 smalldata.txt 
	Total word count 10
	Tally loaded
	Hapax legomena from file 'smalldata.txt':
		line
		test
		this


Note that the second run above is expected to print out no hapax legomena
as there are no words of length 3 in the file whatsoever, so there can't be
any that occur only once!


# Coding it up

I have provided you with a good deal of code to start with.  Your job will
be to take these tools and complete the project.  (This is exactly how things
go in industry, so reading code and integrating partial solutions is excellent
practice.)

Specifically, I have provided you:

* a parser to extract words from text files (you don't need to modify anything here)
* a linked list took to hold the words (you don't need to modify anything here either)
* a partially completed framework to tally up the count of the words
	* you will add in the linked list and parser code here
* a partially complete mainline to initiate the processing for each data file
	* you will add your data allocation and cleanup here, as well as the command line parsing


Your task is to complete the missing portions of the code.  Comments are
provided in the code to guide you to where you will need to make modifications


## Data Structure Approach

In earlier courses you will have briefly encountered *linked lists*.  We will
study them in more detail in the next couple of weeks, but fundamentally
you can think of this as a chain of node elements that store data in each node.

You can "prepend" or "append" to the chain to add a newly allocated node.  This will give you a way to store information about a given word.

Since we want to consider our words ***by length*** it makes sense to have
a separate linked list for each potential length of word.

You therefore should create an **array of pointers to linked lists**,
one linked list for each possible word length
(from length 0 up to a defined maximum length).
Use the lists to store the information about all the words for a given length.

You can then traverse the list for a given length and look for the words that
have a count of one -- these are the hapax legomena.

## Required output

Your output should conform to the sample above.  In particular, there should
be a line of the form "`Hapax legomena from file '`*somedatafile.txt*`':`" that
is immediately followed by the list of hapax legomena (of the indicated length).


# Focus of the grading

Important factors in the grading include (in decreasing order of importance):

* **building correctly** using `make(1)`
	* (Note that whenever you see a term written like this -- a name with a number in brackets immediately after it -- this is a cue that this is a tool installed on the linux machines and there are `man(1)` pages explaining the tool.  Here we are talking about the program `make` which is described in chapter 1 of the man page system.  You can read about it using the command "`man make`".  If the `man(1)` command gives you info from the wrong chapter, you can tell it which chapter you want, *e.g.;* "`man 1 make`".)
	* Code that does not build using `make(1)` **on the linux.socs machines** will get no marks for functionality
		* Be sure to **test your code thoroughly** 
		* Running `make clean` followed by `make` will ensure a complete rebuild
* **integrating** your solution into the provided code
* correctly **identifying the hapax legomena** in sample files
* having **no memory errors or leaks** when run using `valgrind(1)`
	* if things are going well in this regard, the last lines of your
		valgrind output should contain lines similar to this:

	````
	==437155== HEAP SUMMARY:
	==437155==     in use at exit: 0 bytes in 0 blocks
	==437155==   total heap usage: 23 allocs, 23 frees, 10,013 bytes allocated
	==437155== 
	==437155== All heap blocks were freed -- no leaks are possible
	````

	* Note that the numbers on the "`total heap usage`" line are not important, but
		there should be no memory in use at exit
* correctly processing the **command line**
* having **no warnings** when compiling your code
	* all code should be compiled with the flags "`-g -Wall`" to turn on all warnings.  The provided makefile does this for you.
* providing **documentation** through a "`README.txt`" (or "`README.md`") file containing the following information:
	* Your name and student number
	* Any resource you used for assistance
	* The state of your implementation -- whether any functionality is missing or the assignment is complete


# Tools to use to build this assignment

I have provided you a good set of tools to start with.

## C Source Tools

* "`word_extractor.h`" and "`word_extractor.c`":  These two files together form
	a tool to parse the words out of a text file.  ***This tool is provided
	for you to use -- don't modify either of these files***

* "`words_main.c`": This is the mainline of a program that uses the
	word extractor.  It is provided as an example to you of how to use
	the extractor to get the words from the file.  Take a look at the
	code in the `printWordsInFile()` function here to see the creation,
	use and cleanup of the word extractor.

	Note that the word extractor takes a maximum word length as an argument
	to the constructor function.  This is used to allocate a buffer for
	the word to be returned.  **This buffer is overwritten every time a
	new word is read**.  If you want to keep the value of the word for
	use later (such as in your tally) ***you need to make a copy of the
	word to other memory***.

* "`LLNode.h`" and "`LLNode.c`": this is an implementation of a linked list
	adapted slightly from [The Practice of Programming](https://www.oreilly.com/library/view/the-practice-of/9780133133448/)
	by Brian W. Kernighan and Rob Pike, (published in 1999 by Addison-Wesley).

	This is a nice simple and clean implementation of a linked list in C.

	Use the code as is for your work in this assignment (don't modify these files).


* "`word_tally.h`" and "`word_tally.c`": these form a *partially completed* tool for
	you to use for this assignment.  Note that comments marked "TODO" in this
	file to guide you where additional code will be needed.

	In this file you will need to complete the code to *tally* the number of
	times each word is seen -- that is, every time the word is seen you
	will want to increase a counter associated with that word.

	The crux of this assignment is implementing a data structure
	(using linked lists) that you can use to count how often each word occurs.


* "`hapax_main.c`": this is a main routine for you to work with for this assignment.
	Note the comments marked "TODO" here as well.

	As noted above, you will need an *array of linked lists* with a separate linked list
	for the words of each potential length (up to your maximum allowed
	word length).  Once you have set up your array, you
	should be able to use it with the indicated functions noted in the
	comments in this file.

	* You will need to complete the code in "`word_tally.c`" in order
		to populate the linked lists for each length.
	* You will also need to complete the `printHapax()` function to print
		out the *hapax legomena* from each list (that is, the words whose
		occurrence count within the file being read is exactly one).


* "`words_main.c`": this is a small program that demonstrates use of the
	word extractor code provided in "`word_extractor.c`" and "`word_extractor.h`"


* "`makefile`": this is a project management file which can be used with
	the `make(1)` utility to build both the `hapax` executable and
	a `printwords` executable based on the "`words_main.c`" file

* "`test-using-valgrind`": this is a Bourne shell script to run the `hapax`
	executable using `valgrind(1)`.  The `valgrind(1)` utility provides
	memory debugging assistance, including memory leak reporting.  It has
	been installed for you on the `linux.socs` machines in the department.


## Sample Data Files

I have provided three sample text files for you.  You can and should test
your code with additional files of your own making.

* "`smalldata.txt`": this is the tiny text file discussed above.

* "`jabberwocky.txt`": the famous poem from Alice in Wonderland

* "`*-output.txt`": output generated when the solution implementation is run against the above files


# Additional help

Lots of additional help is available for those who need it.

## Code examples

On `linux.socs.uoguelph`, in the course directory "`/home/courses/cis2520`" you
will find example C programs.  For this assignment the relevant ones are are in the directories:
* "`linked-list`": this shows appending and prepending to a linked list using the same code library provided for this assignment
* "`command-line`": this program demonstrates command line handling, where various types of common arguments are used as examples.

You can use code from any of the example programs in your work for this course.  Be sure that you note this in the README file that you will submit.

## Instructor and TA support

You can email [cis2520@socs.uoguelph.ca](mailto:cis2520@socs.uoguelph.ca) which will reach the entire instructional team.  Any email sent to this address will be answered by the first member of the instructional team available to respond.  You will get a response within 24 hours, and probably sooner.  Note that staff are not generally available outside of daytime working hours (for this or any course), so it is in your interest to start work early so that if you have questions you can ask them in time to get a good response.

Additional support is available during lab times when teaching staff will be available to answer lab related questions and general questions if time permits.  Note that lab exercises are designed specifically to build your skills within the focus of current and upcoming assignments.


